import requests
import json
import time
import torch
import numpy as np
from PIL import Image
from io import BytesIO
import os
try:
    import folder_paths
except ImportError:
    # folder_paths åªåœ¨ ComfyUI ç¯å¢ƒä¸­å¯ç”¨
    folder_paths = None
import base64
import tempfile

def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {
            "default_model": "Qwen/Qwen-Image",
            "timeout": 720,
            "image_download_timeout": 30,
            "default_prompt": "A beautiful landscape"
        }

def save_config(config: dict) -> bool:
    config_path = os.path.join(os.path.dirname(__file__), 'config.json')
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
        return False

def save_api_token(token):
    token_path = os.path.join(os.path.dirname(__file__), '.qwen_token')
    try:
        with open(token_path, 'w', encoding='utf-8') as f:
            f.write(token)
    except Exception as e:
        print(f"ä¿å­˜tokenå¤±è´¥(.qwen_token): {e}")
    try:
        cfg = load_config()
        cfg["api_token"] = token
        if save_config(cfg):
            return True
        return False
    except Exception as e:
        print(f"ä¿å­˜tokenå¤±è´¥(config.json): {e}")
        return False

def load_api_token():
    token_path = os.path.join(os.path.dirname(__file__), '.qwen_token')
    try:
        cfg = load_config()
        token_from_cfg = cfg.get("api_token", "").strip()
        if token_from_cfg:
            return token_from_cfg
    except Exception as e:
        print(f"è¯»å–config.jsonä¸­çš„tokenå¤±è´¥: {e}")
    try:
        if os.path.exists(token_path):
            with open(token_path, 'r', encoding='utf-8') as f:
                token = f.read().strip()
                return token if token else ""
        return ""
    except Exception as e:
        print(f"åŠ è½½tokenå¤±è´¥: {e}")
        return ""

def tensor_to_base64_url(image_tensor):
    try:
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor.squeeze(0)
        
        if image_tensor.max() <= 1.0:
            image_np = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        else:
            image_np = image_tensor.cpu().numpy().astype(np.uint8)
        
        pil_image = Image.fromarray(image_np)
        
        buffer = BytesIO()
        pil_image.save(buffer, format='JPEG', quality=85)
        img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        return f"data:image/jpeg;base64,{img_base64}"
        
    except Exception as e:
        print(f"å›¾åƒè½¬æ¢å¤±è´¥: {e}")
        raise Exception(f"å›¾åƒæ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")

class QwenImageNode:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        config = load_config()
        saved_token = load_api_token()
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_prompt", "A beautiful landscape")
                }),
                "api_token": ("STRING", {
                    "default": saved_token,
                    "placeholder": "è¯·è¾“å…¥æ‚¨çš„é­”æ­API Token"
                }),
            },
            "optional": {
                "model": ("STRING", {
                    "default": config.get("default_model", "Qwen/Qwen-Image")
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_negative_prompt", "")
                }),
                "width": ("INT", {
                    "default": config.get("default_width", 512),
                    "min": 64,
                    "max": 2048,
                    "step": 64
                }),
                "height": ("INT", {
                    "default": config.get("default_height", 512),
                    "min": 64,
                    "max": 2048,
                    "step": 64
                }),
                "seed": ("INT", {
                    "default": config.get("default_seed", -1),
                    "min": -1,
                    "max": 2147483647
                }),
                "steps": ("INT", {
                    "default": config.get("default_steps", 30),
                    "min": 1,
                    "max": 100
                }),
                "guidance": ("FLOAT", {
                    "default": config.get("default_guidance", 7.5),
                    "min": 1.5,
                    "max": 20.0,
                    "step": 0.1
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "generate_image"
    CATEGORY = "QwenImage"
    
    def generate_image(self, prompt, api_token, model="Qwen/Qwen-Image", negative_prompt="", width=512, height=512, seed=-1, steps=30, guidance=7.5):
        config = load_config()
        if not api_token or api_token.strip() == "":
            raise Exception("è¯·è¾“å…¥æœ‰æ•ˆçš„API Token")
        saved_token = load_api_token()
        if api_token != saved_token:
            if save_api_token(api_token):
                print("API Tokenå·²è‡ªåŠ¨ä¿å­˜")
            else:
                print("API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        try:
            url = 'https://api-inference.modelscope.cn/v1/images/generations'
            payload = {
                'model': model,
                'prompt': prompt,
                'size': f"{width}x{height}",
                'steps': steps,
                'guidance': guidance
            }
            if negative_prompt.strip():
                payload['negative_prompt'] = negative_prompt
                print(f"ğŸš« è´Ÿå‘æç¤ºè¯: {negative_prompt}")
            if seed != -1:
                payload['seed'] = seed
                print(f"ğŸ¯ ä½¿ç”¨æŒ‡å®šç§å­: {seed}")
            else:
                import random
                random_seed = random.randint(0, 2147483647)
                payload['seed'] = random_seed
                print(f"ğŸ² ä½¿ç”¨éšæœºç§å­: {random_seed}")
            print(f"ğŸ“ å›¾åƒå°ºå¯¸: {width}x{height}")
            print(f"ğŸ”§ é‡‡æ ·æ­¥æ•°: {steps}")
            print(f"ğŸ¨ å¼•å¯¼ç³»æ•°: {guidance}")
            headers = {
                'Authorization': f'Bearer {api_token}',
                'Content-Type': 'application/json',
                'X-ModelScope-Async-Mode': 'true'
            }
            submission_response = requests.post(
                url, 
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8'), 
                headers=headers,
                timeout=config.get("timeout", 60)
            )
            if submission_response.status_code == 400:
                print("æäº¤å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æœ€å°å‚æ•°é‡è¯•...")
                minimal_payload = {
                    'model': model,
                    'prompt': prompt
                }
                submission_response = requests.post(
                    url,
                    data=json.dumps(minimal_payload, ensure_ascii=False).encode('utf-8'),
                    headers=headers,
                    timeout=config.get("timeout", 60)
                )
            if submission_response.status_code != 200:
                raise Exception(f"APIè¯·æ±‚å¤±è´¥: {submission_response.status_code}, {submission_response.text}")
            submission_json = submission_response.json()
            image_url = None
            if 'task_id' in submission_json:
                task_id = submission_json['task_id']
                print(f"ğŸ•’ å·²æäº¤ä»»åŠ¡ï¼Œä»»åŠ¡ID: {task_id}ï¼Œå¼€å§‹è½®è¯¢...")
                poll_start = time.time()
                max_wait_seconds = max(60, config.get('timeout', 720))
                while True:
                    task_resp = requests.get(
                        f"https://api-inference.modelscope.cn/v1/tasks/{task_id}",
                        headers={
                            'Authorization': f'Bearer {api_token}',
                            'X-ModelScope-Task-Type': 'image_generation'
                        },
                        timeout=config.get("image_download_timeout", 120)
                    )
                    if task_resp.status_code != 200:
                        raise Exception(f"ä»»åŠ¡æŸ¥è¯¢å¤±è´¥: {task_resp.status_code}, {task_resp.text}")
                    task_data = task_resp.json()
                    status = task_data.get('task_status')
                    if status == 'SUCCEED':
                        output_images = task_data.get('output_images') or []
                        if not output_images:
                            raise Exception("ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›å›¾ç‰‡URL")
                        image_url = output_images[0]
                        print("ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹ä¸‹è½½å›¾ç‰‡...")
                        break
                    if status == 'FAILED':
                        raise Exception(f"ä»»åŠ¡å¤±è´¥: {task_data}")
                    if time.time() - poll_start > max_wait_seconds:
                        raise Exception("ä»»åŠ¡è½®è¯¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–é™ä½å¹¶å‘")
                    time.sleep(5)
            elif 'images' in submission_json and len(submission_json['images']) > 0:
                image_url = submission_json['images'][0]['url']
                print(f"ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡...")
            else:
                raise Exception(f"æœªè¯†åˆ«çš„APIè¿”å›æ ¼å¼: {submission_json}")
            img_response = requests.get(image_url, timeout=config.get("image_download_timeout", 30))
            if img_response.status_code != 200:
                raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_response.status_code}")
            pil_image = Image.open(BytesIO(img_response.content))
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            image_np = np.array(pil_image).astype(np.float32) / 255.0
            image_tensor = torch.from_numpy(image_np)[None,]
            print(f"ğŸ‰ å›¾ç‰‡å¤„ç†å®Œæˆï¼")
            return (image_tensor,)
        except Exception as e:
            print(f"Qwen-Image APIè°ƒç”¨å¤±è´¥: {str(e)}")
            error_image = Image.new('RGB', (width, height), color='red')
            error_np = np.array(error_image).astype(np.float32) / 255.0
            error_tensor = torch.from_numpy(error_np)[None,]
            return (error_tensor,)

class QwenImageEditNode:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        config = load_config()
        saved_token = load_api_token()
        return {
            "required": {
                "image": ("IMAGE",),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä¿®æ”¹å›¾ç‰‡ä¸­çš„å†…å®¹"
                }),
                "api_token": ("STRING", {
                    "default": saved_token,
                    "placeholder": "è¯·è¾“å…¥æ‚¨çš„é­”æ­API Token"
                }),
            },
            "optional": {
                "image_2": ("IMAGE",),
                "image_3": ("IMAGE",),
                "model": ("STRING", {
                    "default": "Qwen/Qwen-Image-Edit"
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": ""
                }),
                "width": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 1664,
                    "step": 8
                }),
                "height": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 1664,
                    "step": 8
                }),
                "steps": ("INT", {
                    "default": 30,
                    "min": 1,
                    "max": 100,
                    "step": 1
                }),
                "guidance": ("FLOAT", {
                    "default": 3.5,
                    "min": 1.5,
                    "max": 20.0,
                    "step": 0.1
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647
                }),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("edited_image",)
    FUNCTION = "edit_image"
    CATEGORY = "QwenImage"

    def edit_image(self, image, prompt, api_token, model="Qwen/Qwen-Image-Edit", negative_prompt="", 
                   width=512, height=512, steps=30, guidance=3.5, seed=-1, image_2=None, image_3=None):
        config = load_config()
        if not api_token or api_token.strip() == "":
            raise Exception("è¯·è¾“å…¥æœ‰æ•ˆçš„API Token")
        saved_token = load_api_token()
        if api_token != saved_token:
            if save_api_token(api_token):
                print("API Tokenå·²è‡ªåŠ¨ä¿å­˜")
            else:
                print("API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")

        try:
            # å¤„ç†ä¸Šä¼ å¤šå¼ å›¾ç‰‡çš„å‡½æ•°
            def upload_single_image(img_tensor, index):
                temp_path = None
                img_url = None
                try:
                    # ä¿å­˜å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶
                    temp_path = os.path.join(tempfile.gettempdir(), f"qwen_edit_temp_{index}_{int(time.time())}.jpg")
                    if len(img_tensor.shape) == 4:
                        img = img_tensor[0]
                    else:
                        img = img_tensor
                    
                    i = 255. * img.cpu().numpy()
                    img_pil = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
                    img_pil.save(temp_path)
                    print(f"å›¾åƒ{index}å·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {temp_path}")
                    
                    # ä¸Šä¼ å›¾åƒåˆ°kefan.cnè·å–URL
                    upload_url = 'https://ai.kefan.cn/api/upload/local'
                    with open(temp_path, 'rb') as img_file:
                        files = {'file': img_file}
                        upload_response = requests.post(
                            upload_url,
                            files=files,
                            timeout=30
                        )
                        if upload_response.status_code == 200:
                            upload_data = upload_response.json()
                            if upload_data.get('success') == True and 'data' in upload_data:
                                img_url = upload_data['data']
                                print(f"å›¾åƒ{index}å·²ä¸Šä¼ æˆåŠŸï¼Œè·å–URL: {img_url}")
                            else:
                                print(f"å›¾åƒ{index}ä¸Šä¼ è¿”å›é”™è¯¯: {upload_response.text}")
                        else:
                            print(f"å›¾åƒ{index}ä¸Šä¼ å¤±è´¥: {upload_response.status_code}, {upload_response.text}")
                except Exception as e:
                    print(f"å›¾åƒ{index}ä¸Šä¼ å¼‚å¸¸: {str(e)}")
                
                return temp_path, img_url
            
            # ä¸Šä¼ ä¸»å›¾åƒ
            temp_img_path, image_url = upload_single_image(image, 1)
            temp_paths = [temp_img_path]
            
            # ä¸Šä¼ ç¬¬äºŒå¼ å›¾åƒ(å¦‚æœæä¾›)
            image_2_url = None
            if image_2 is not None:
                temp_path_2, image_2_url = upload_single_image(image_2, 2)
                if temp_path_2:
                    temp_paths.append(temp_path_2)
            
            # ä¸Šä¼ ç¬¬ä¸‰å¼ å›¾åƒ(å¦‚æœæä¾›)
            image_3_url = None
            if image_3 is not None:
                temp_path_3, image_3_url = upload_single_image(image_3, 3)
                if temp_path_3:
                    temp_paths.append(temp_path_3)
            
            # æ„å»ºpayload - æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå¤šå›¾ä½¿ç”¨ image_url æ•°ç»„
            # æ”¶é›†æ‰€æœ‰å›¾ç‰‡URL
            image_urls = []
            image_base64s = []
            
            if image_url:
                image_urls.append(image_url)
            else:
                image_base64s.append(tensor_to_base64_url(image))
            
            # æ·»åŠ ç¬¬äºŒå¼ å›¾ç‰‡
            if image_2 is not None:
                if image_2_url:
                    image_urls.append(image_2_url)
                    print(f"âœ… å·²æ·»åŠ ç¬¬äºŒå¼ å›¾ç‰‡URL")
                else:
                    image_base64s.append(tensor_to_base64_url(image_2))
                    print(f"âœ… å·²æ·»åŠ ç¬¬äºŒå¼ å›¾ç‰‡(base64)")
            
            # æ·»åŠ ç¬¬ä¸‰å¼ å›¾ç‰‡
            if image_3 is not None:
                if image_3_url:
                    image_urls.append(image_3_url)
                    print(f"âœ… å·²æ·»åŠ ç¬¬ä¸‰å¼ å›¾ç‰‡URL")
                else:
                    image_base64s.append(tensor_to_base64_url(image_3))
                    print(f"âœ… å·²æ·»åŠ ç¬¬ä¸‰å¼ å›¾ç‰‡(base64)")
            
            # æ„å»ºpayload
            payload = {
                'model': model,
                'prompt': prompt
            }
            
            # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œimage_url å§‹ç»ˆä½¿ç”¨æ•°ç»„æ ¼å¼ï¼ˆå³ä½¿å•å¼ å›¾ç‰‡ï¼‰
            if len(image_urls) > 0:
                payload['image_url'] = image_urls  # ç»Ÿä¸€ä½¿ç”¨æ•°ç»„æ ¼å¼
                print(f"ğŸ“¸ ä½¿ç”¨URLæ¨¡å¼ï¼Œå…±{len(image_urls)}å¼ å›¾ç‰‡: {image_urls}")
            elif len(image_base64s) > 0:
                # Base64æ¨¡å¼ä¹Ÿå°è¯•ä½¿ç”¨æ•°ç»„
                payload['image'] = image_base64s
                print(f"ğŸ“¸ ä½¿ç”¨Base64æ¨¡å¼ï¼Œå…±{len(image_base64s)}å¼ å›¾ç‰‡")
            
            if negative_prompt.strip():
                payload['negative_prompt'] = negative_prompt
                print(f"ğŸš« è´Ÿå‘æç¤ºè¯: {negative_prompt}")
                
            # æ·»åŠ æ–°å‚æ•°
            if width != 512 or height != 512:
                size = f"{width}x{height}"
                payload['size'] = size
                print(f"ğŸ“ å›¾åƒå°ºå¯¸: {size}")
                
            if steps != 30:
                payload['steps'] = steps
                print(f"é‡‡æ ·æ­¥æ•°: {steps}")
                
            if guidance != 3.5:
                payload['guidance'] = guidance
                print(f"ğŸ§­ å¼•å¯¼ç³»æ•°: {guidance}")
                
            if seed != -1:
                payload['seed'] = seed
                print(f"ğŸ² éšæœºç§å­: {seed}")
            
            headers = {
                'Authorization': f'Bearer {api_token}',
                'Content-Type': 'application/json',
                'X-ModelScope-Async-Mode': 'true'
            }
            
            print(f"å¼€å§‹ç¼–è¾‘å›¾ç‰‡...")
            print(f"ç¼–è¾‘æç¤º: {prompt}")
            
            url = 'https://api-inference.modelscope.cn/v1/images/generations'
            submission_response = requests.post(
                url,
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                headers=headers,
                timeout=config.get("timeout", 60)
            )
            
            if submission_response.status_code != 200:
                raise Exception(f"APIè¯·æ±‚å¤±è´¥: {submission_response.status_code}, {submission_response.text}")
                
            submission_json = submission_response.json()
            result_image_url = None
            
            if 'task_id' in submission_json:
                task_id = submission_json['task_id']
                print(f"ğŸ•’ å·²æäº¤ä»»åŠ¡ï¼Œä»»åŠ¡ID: {task_id}ï¼Œå¼€å§‹è½®è¯¢...")
                poll_start = time.time()
                max_wait_seconds = max(60, config.get('timeout', 720))
                
                while True:
                    task_resp = requests.get(
                        f"https://api-inference.modelscope.cn/v1/tasks/{task_id}",
                        headers={
                            'Authorization': f'Bearer {api_token}',
                            'X-ModelScope-Task-Type': 'image_generation'
                        },
                        timeout=config.get("image_download_timeout", 120)
                    )
                    
                    if task_resp.status_code != 200:
                        raise Exception(f"ä»»åŠ¡æŸ¥è¯¢å¤±è´¥: {task_resp.status_code}, {task_resp.text}")
                        
                    task_data = task_resp.json()
                    status = task_data.get('task_status')
                    
                    if status == 'SUCCEED':
                        output_images = task_data.get('output_images') or []
                        if not output_images:
                            raise Exception("ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›å›¾ç‰‡URL")
                        result_image_url = output_images[0]
                        print("ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹ä¸‹è½½ç¼–è¾‘åçš„å›¾ç‰‡...")
                        break
                        
                    if status == 'FAILED':
                        error_message = task_data.get('errors', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                        error_code = task_data.get('errors', {}).get('code', 'æœªçŸ¥é”™è¯¯ç ')
                        raise Exception(f"ä»»åŠ¡å¤±è´¥: é”™è¯¯ç  {error_code}, é”™è¯¯ä¿¡æ¯: {error_message}")
                        
                    if time.time() - poll_start > max_wait_seconds:
                        raise Exception("ä»»åŠ¡è½®è¯¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–é™ä½å¹¶å‘")
                        
                    time.sleep(5)
            else:
                raise Exception(f"æœªè¯†åˆ«çš„APIè¿”å›æ ¼å¼: {submission_json}")
                
            img_response = requests.get(result_image_url, timeout=config.get("image_download_timeout", 30))
            if img_response.status_code != 200:
                raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_response.status_code}")
                
            pil_image = Image.open(BytesIO(img_response.content))
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
                
            image_np = np.array(pil_image).astype(np.float32) / 255.0
            image_tensor = torch.from_numpy(image_np)[None,]
            
            # æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶
            for temp_path in temp_paths:
                if temp_path and os.path.exists(temp_path):
                    try:
                        os.remove(temp_path)
                    except:
                        pass
            
            print(f"ğŸ‰ å›¾ç‰‡ç¼–è¾‘å®Œæˆï¼")
            return (image_tensor,)
            
        except Exception as e:
            print(f"Qwen-Image-Edit APIè°ƒç”¨å¤±è´¥: {str(e)}")
            # è¿”å›åŸå›¾åƒä½œä¸ºé”™è¯¯å›é€€
            return (image.unsqueeze(0),)

NODE_CLASS_MAPPINGS = {
    "QwenImageNode": QwenImageNode,
    "QwenImageEditNode": QwenImageEditNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "QwenImageNode": "Qwen-Image ç”Ÿå›¾èŠ‚ç‚¹",
    "QwenImageEditNode": "Qwen-Image å›¾åƒç¼–è¾‘èŠ‚ç‚¹"
} 